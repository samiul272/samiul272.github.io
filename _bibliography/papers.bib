---
@article{wan2023efficient,
  title={Efficient Large Language Models: A Survey},
  author={Wan, Zhongwei and Wang, Xin and Liu, Che and Alam, Samiul and Zheng, Yu and Qu, Zhongnan and Yan, Shen and Zhu, Yi and Zhang, Quanlu and Chowdhury, Mosharaf and others},
  year={2023},
  arxiv = {2312.03863},
  pdf = {https://arxiv.org/pdf/2312.03863},
  doi={https://doi.org/10.48550/arXiv.2312.03863},
  abstract={Large Language Models (LLMs) have demonstrated remarkable capabilities in important tasks such as natural language understanding, language generation, and complex reasoning and have the potential to make a substantial impact on our society. Such capabilities, however, come with the considerable resources they demand, highlighting the strong need to develop effective techniques for addressing their efficiency challenges. In this survey, we provide a systematic and comprehensive review of efficient LLMs research. We organize the literature in a taxonomy consisting of three main categories, covering distinct yet interconnected efficient LLMs topics from model-centric, data-centric, and framework-centric perspective, respectively. We have also created a GitHub repository where we compile the papers featured in this survey at https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey, this https URL, and will actively maintain this repository and incorporate new research as it emerges. We hope our survey can serve as a valuable resource to help researchers and practitioners gain a systematic understanding of the research developments in efficient LLMs and inspire them to contribute to this important and exciting field.},
  preview={effllm.png},
  selected={true},
}

@article{alam2023sparse,
  author={Alam, Samiul and Amin, Md. Rafiul and Faghih, Rose T.},
  journal={IEEE Open Journal of Engineering in Medicine and Biology},
  title={Sparse Multichannel Decomposition of Electrodermal Activity With Physiological Priors},
  year={2023},
  volume={4},
  pages={234-250},
  abstract={Goal: Inferring autonomous nervous system (ANS) activity is a challenging issue and has critical applications in stress regulation. Sweat secretions caused by ANS activity influence the electrical conductance of the skin. Therefore, the variations in skin conductance (SC) measurements reflect the sudomotor nerve activity (SMNA) and can be used to infer the underlying ANS activity. These variations are strongly correlated with emotional arousal as well as thermoregulation. However, accurately recovering ANS activity and the corresponding state-space system from a single channel signal is difficult due to artifacts introduced by measurement noise. To minimize the impact of noise on inferring ANS activity, we utilize multiple channels of SC data. Methods: We model skin conductance using a second-order differential equation incorporating a time-shifted sparse impulse train input in combination with independent cubic basis spline functions. Finally, we develop a block coordinate descent method for SC signal decomposition by employing a generalized cross-validation sparse recovery approach while including physiological priors. Results: We analyze the experimental data to validate the performance of the proposed algorithm. We demonstrate its capacity to recover the ANS activations, the underlying physiological system parameters, and both tonic and phasic components. Finally, we present an overview of the algorithm's comparative performance under varying conditions and configurations to substantiate its ability to accurately model ANS activity. Our results show that our algorithm performs better in terms of multiple metrics like noise performance, AUC score, the goodness of fit of reconstructed signal, and lower missing impulses compared with the single channel decomposition approach. Conclusion: In this study, we highlight the challenges and benefits of concurrent decomposition and deconvolution of multichannel SC signals.},
  doi={10.1109/OJEMB.2023.3332839},
  ISSN={2644-1276},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10319803},
  selected={true},
  preview={sparse.jpg}
  }


@article{alam2023fedaiot,
  title={FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things},
  author={Alam, Samiul and Zhang, Tuo and Feng, Tiantian and Shen, Hui and Cao, Zhichao and Zhao, Dong and Ko, JeongGil and Somasundaram, Kiran and Narayanan, Shrikanth S and Avestimehr, Salman and others},
  doi={https://doi.org/10.48550/arXiv.2310.00109},
  pdf = {https://arxiv.org/pdf/2310.00109},
  year={2023},
  arxiv = {2310.00109},
  preview = {fedaiot.png},
  abstract = {There is a significant relevance of federated learning (FL) in the realm of Artificial Intelligence of Things (AIoT). However, most existing FL works are not conducted on datasets collected from authentic IoT devices that capture unique modalities and inherent challenges of IoT data. In this work, we introduce FedAIoT, an FL benchmark for AIoT to fill this critical gap. FedAIoT includes eight datatsets collected from a wide range of IoT devices. These datasets cover unique IoT modalities and target representative applications of AIoT. FedAIoT also includes a unified end-to-end FL framework for AIoT that simplifies benchmarking the performance of the datasets. Our benchmark results shed light on the opportunities and challenges of FL for AIoT. We hope FedAIoT could serve as an invaluable resource to foster advancements in the important field of FL for AIoT. The repository of FedAIoT is maintained at https://github.com/AIoT-MLSys-Lab/FedAIoT}
}

@inproceedings{rakib23_interspeech,
  author={Fazle Rabbi Rakib and Souhardya Saha Dip and Samiul Alam and Nazia Tasnim and Md. Istiak Hossain Shihab and Md. Nazmuddoha Ansary and Syed Mobassir Hossen and Marsia Haque Meghla and Mamunur Mamun and Farig Sadeque and Sayma Sultana Chowdhury and Tahsin Reasat and Asif Sushmit and Ahmed Imtiaz Humayun},
  title={{OOD-Speech: A Large Bengali Speech Recognition Dataset for Out-of-Distribution Benchmarking}},
  year={2023},
  booktitle={Proc. INTERSPEECH 2023},
  pages={879--883},
  doi={10.21437/Interspeech.2023-2585},
  selected={true},
  arxiv = {2305.09688},
  preview = {oodspeech.png}
}

@article{zhang2023gpt,
  title={Gpt-fl: Generative pre-trained model-assisted federated learning},
  author={Zhang, Tuo and Feng, Tiantian and Alam, Samiul and Zhang, Mi and Narayanan, Shrikanth S and Avestimehr, Salman},
  journal={arXiv preprint arXiv:2306.02210},
  year={2023}
}

@phdthesis{alam2023federated,
  title={Federated Learning Benchmarks and Frameworks for Artificial Intelligence of Things},
  author={Alam, Samiul},
  year={2023},
  school={Michigan State University}
}---

@inproceedings{zhang2022fedaudio,
    title = {FedAudio: A Federated Learning Benchmark for Audio Tasks},
    author = {Zhang, Tuo and Feng, Tiantian and Alam, Samiul and Lee, Sunwoo and Zhang, Mi and Narayanan, Shrikanth S and Avestimehr, Salman},
    booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},
    year = {2023},
    html = {https://arxiv.org/abs/2210.15707},
    arxiv = {2210.15707},
    abstract = {Federated learning (FL) has gained substantial attention in recent years due to the data privacy concerns related to the pervasiveness of consumer devices that continuously collect data from users. While a number of FL benchmarks have been developed to facilitate FL research, none of them include audio data and audio-related tasks. In this paper, we fill this critical gap by introducing a new FL benchmark for audio tasks which we refer to as FedAudio. FedAudio includes four representative and commonly used audio datasets from three important audio tasks that are well aligned with FL use cases. In particular, a unique contribution of FedAudio is the introduction of data noises and label errors to the datasets to emulate challenges when deploying FL systems in real-world settings. FedAudio also includes the benchmark results of the datasets and a PyTorch library with the objective of facilitating researchers to fairly compare their algorithms. We hope FedAudio could act as a catalyst to inspire new FL research for audio tasks and thus benefit the acoustic and speech research community. The datasets and benchmark results can be accessed at this https URL. },
}

@inproceedings{alam2022fedrolex,
    title = {FedRolex: Model-Heterogeneous Federated Learning with Rolling Sub-Model Extraction},
    author = {Alam, Samiul and Liu, Luyang and Yan, Ming and Zhang, Mi},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2022},
    selected = {true},
    pdf = {https://openreview.net/pdf?id=OtxyysUdBE},
    html = {https://openreview.net/forum?id=OtxyysUdBE},
    arxiv = {2212.01548},
    preview = {fedrolex.png},
    abstract = {Most cross-device federated learning (FL) studies focus on the model-homogeneous setting where the global server model and local client models are identical. However, such constraint not only excludes low-end clients who would otherwise make unique contributions to model training but also restrains clients from training large models due to on-device resource bottlenecks. In this work, we propose FedRolex, a partial training (PT)-based approach that enables model-heterogeneous FL and can train a global server model larger than the largest client model. At its core, FedRolex employs a rolling sub-model extraction scheme that allows different parts of the global server model to be evenly trained, which mitigates the client drift induced by the inconsistency between individual client models and server model architectures. Empirically, we show that FedRolex outperforms state-of-the-art PT-based model-heterogeneous FL methods (e.g. Federated Dropout) and reduces the gap between model-heterogeneous and model-homogeneous FL, especially under the large-model large-dataset regime. In addition, we provide theoretical statistical analysis on its advantage over Federated Dropout. Lastly, we evaluate FedRolex on an emulated real-world device distribution to show that FedRolex can enhance the inclusiveness of FL and boost the performance of low-end devices that would otherwise not benefit from FL. Our code is available at: https://github.com/AIoT-MLSys-Lab/FedRolex.},
}

@inproceedings{Jingwei2022fedsea,
    author = {Sun, Jingwei and Li, Ang and Duan, Lin and Alam, Samiul and Deng, Xuliang and GUO, Xin and Wang, Haiming and Gorlatova, Maria and Zhang, Mi and Chen, Yiran},
    year = {2022},
    month = {12},
    booktitle = {ACM Conference on Embedded Networked Sensor Systems},
    title = {FedSEA: A Semi-Asynchronous Federated Learning Framework for Extremely Heterogeneous Devices},
    abstract = {Federated learning (FL) has attracted increasing attention as a promising technique to drive a vast number of edge devices with artificial intelligence. However, it is very challenging to guarantee the efficiency of a FL system in practice due to the heterogeneous computation resources on different devices. To improve the efficiency of FL systems in the real world, asynchronous FL (AFL) and semi-asynchronous FL (SAFL) methods are proposed such that the server does not need to wait for stragglers. However, existing AFL and SAFL systems suffer from poor accuracy and low efficiency in realistic settings where the data is non-IID distributed across devices and the on-device resources are extremely heterogeneous. In this work, we propose FedSEA - a semi-asynchronous FL framework for extremely heterogeneous devices. We theoretically disclose that the unbalanced aggregation frequency is a root cause of accuracy drop in SAFL. Based on this analysis, we design a training configuration scheduler to balance the aggregation frequency of devices such that the accuracy can be improved. To improve the efficiency of the system in realistic settings where the devices have dynamic on-device resource availability, we design a scheduler that can efficiently predict the arriving time of local updates from devices and adjust the synchronization time point according to the devices' predicted arriving time. We also consider the extremely heterogeneous settings where there exist extremely lagging devices that take hundreds of times as long as the training time of the other devices. In the real world, there might be even some extreme stragglers which are not capable of training the global model. To enable these devices to join in training without impairing the systematic efficiency, Fed-SEA enables these extreme stragglers to conduct local training on much smaller models. Our experiments show that compared with status quo approaches, FedSEA improves the inference accuracy by 44.34% and reduces the systematic time cost and local training time cost by 87.02× and 792.9×. FedSEA also reduces the energy consumption of the devices with extremely limited resources by 752.9×},
    html = {https://dl.acm.org/doi/10.1145/3560905.3568538},
    pdf = {https://dl.acm.org/doi/pdf/10.1145/3560905.3568538},
}

@article{alam2022bengali,
    title = {Bengali Common Voice Speech Dataset for Automatic Speech Recognition},
    author = {Alam, Samiul and Sushmit, Asif and Abdullah, Zaowad and Nakkhatra, Shahrin and Ansary, MD and Hossen, Syed Mobassir and Mehnaz, Sazia Morshed and Reasat, Tahsin and Humayun, Ahmed Imtiaz},
    journal = {arXiv preprint arXiv:2206.14053},
    year = {2022},
    selected = {true},
    abstract = {Bengali is one of the most spoken languages in the world with over 300 million speakers globally. Despite its popularity, research into the development of Bengali speech recognition systems is hindered due to the lack of diverse open-source datasets. As a way forward, we have crowdsourced the Bengali Common Voice Speech Dataset, which is a sentence-level automatic speech recognition corpus. Collected on the Mozilla Common Voice platform, the dataset is part of an ongoing campaign that has led to the collection of over 400 hours of data in 2 months and is growing rapidly. Our analysis shows that this dataset has more speaker, phoneme, and environmental diversity compared to the OpenSLR Bengali ASR dataset, the largest existing open-source Bengali speech dataset. We present insights obtained from the dataset and discuss key linguistic challenges that need to be addressed in future versions. Additionally, we report the current performance of a few Automatic Speech Recognition (ASR) algorithms and set a benchmark for future research.},
    html = {https://arxiv.org/abs/2206.14053},
    arxiv = {2206.14053},
    preview = {dlsprint.jpg},
}

@article{alam2021large,
    title = {A large multi-target dataset of common bengali handwritten graphemes},
    author = {Alam, Samiul and Reasat, Tahsin and Sushmit, Asif Shahriyar and Siddique, Sadi Mohammad and Rahman, Fuad and Hasan, Mahady and Humayun, Ahmed Imtiaz},
    booktitle = {International Conference on Document Analysis and Recognition},
    pages = {383--398},
    year = {2021},
    selected = {true},
    organization = {Springer, Cham},
    selected = {true},
    html = {https://link.springer.com/chapter/10.1007/978-3-030-86337-1_26},
    arxiv = {2010.00170},
    pdf = {https://link.springer.com/content/pdf/10.1007/978-3-030-86337-1.pdf},
    preview = {grapheme.png},
    abstract = {Latin has historically led the state-of-the-art in handwritten optical character recognition (OCR) research. Adapting existing systems from Latin to alpha-syllabary languages is particularly challenging due to a sharp contrast between their orthographies. Due to a cursive writing system and frequent use of diacritics, the segmentation and/or alignment of graphical constituents with corresponding characters becomes significantly convoluted. We propose a labeling scheme based on graphemes (linguistic segments of word formation) that makes segmentation inside alpha-syllabary words linear and present the first dataset of Bengali handwritten graphemes that are commonly used in everyday context. The dataset contains 411k curated samples of 1295 unique commonly used Bengali graphemes. Additionally, the test set contains 900 uncommon Bengali graphemes for out of dictionary performance evaluation. The dataset is open-sourced as a part of a public Handwritten Grapheme Classification Challenge on Kaggle to benchmark vision algorithms for multi-target grapheme classification. The unique graphemes present in this dataset are selected based on commonality in the Google Bengali ASR corpus. From competition proceedings, we see that deep learning methods can generalize to a large span of out of dictionary graphemes which are absent during training (Kaggle Competition kaggle.com/c/bengaliai-cv19, Supplementary materials and Appendix https://github.com/AhmedImtiazPrio/ICDAR2021supplementary).},
}

@article{alam2018numtadb,
    title = {Numtadb-assembled bengali handwritten digits},
    author = {Alam, Samiul and Reasat, Tahsin and Doha, Rashed Mohammad and Humayun, Ahmed Imtiaz},
    journal = {arXiv preprint arXiv:1806.02452},
    year = {2018},
    selected = {true},
    html = {https://arxiv.org/abs/1806.02452},
    arxiv = {1806.02452},
    pdf = {https://arxiv.org/pdf/1806.02452},
    preview = {numta.gif},
    abstract = {To benchmark Bengali digit recognition algorithms, a large publicly available dataset is required which is free from biases originating from geographical location, gender, and age. With this aim in mind, NumtaDB, a dataset consisting of more than 85,000 images of hand-written Bengali digits, has been assembled. This paper documents the collection and curation process of numerals along with the salient statistics of the dataset. },
}

@article{kamran2018ai,
    title = {AI Learns to Recognize Bengali Handwritten Digits: Bengali. AI Computer Vision Challenge 2018},
    author = {Kamran, Sharif Amit and Humayun, Ahmed Imtiaz and Alam, Samiul and Doha, Rashed Mohammad and Mandal, Manash Kumar and Reasat, Tahsin and Rahman, Fuad},
    journal = {arXiv preprint arXiv:1810.04452},
    year = {2018}
}

@article{al2018predictive,
    title = {Predictive real-time beat tracking from music for embedded application},
    author = {Al-Hussaini, Irfan and Humayun, Ahmed Imtiaz and Alam, Samiul and Foysal, Shariful Islam and Al Masud, Abdullah and Mahmud, Arafat and Chowdhury, Rakibul Islam and Ibtehaz, Nabil and Zaman, Sums Uz and Hyder, Rakib and others},
    booktitle = {2018 IEEE Conference on multimedia information processing and retrieval (MIPR)},
    pages = {297--300},
    year = {2018},
    organization = {IEEE},
    html = {https://ieeexplore.ieee.org/document/8397024},
    pdf = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8397024},
    preview = {spcup.png},
    abstract = {Beat tracking from music signals has significant importance in multimedia information retrieval systems, especially in cover song detection. A predictive real-time beat tracking system can also be used to assist musicians performing live. In this paper we present a real-time beat tracking algorithm, fast enough to be implemented on an embedded system. The onset of a note is detected using a maximum filter approach that suppresses the effect of vibrato. Beats are predicted a second in advance using a causal variant of Dynamic Programming. We have employed an onset memoization algorithm, to reduce the computational resources required. Raspberry Pi was chosen as our preferred development board. We have demonstrated through experimental results that the proposed approach can satisfactorily estimate beat positions from a music signal in real-time with an average continuity score (AMLt) of 0.67.},
}